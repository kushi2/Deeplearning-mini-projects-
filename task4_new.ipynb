{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = open('pg18857.txt', 'r').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ï»¿Project',\n",
       " \"Gutenberg's\",\n",
       " 'A',\n",
       " 'Journey',\n",
       " 'to',\n",
       " 'the',\n",
       " 'Centre',\n",
       " 'of',\n",
       " 'the',\n",
       " 'Earth,',\n",
       " 'by',\n",
       " 'Jules',\n",
       " 'Verne',\n",
       " 'This',\n",
       " 'eBook',\n",
       " 'is',\n",
       " 'for',\n",
       " 'the',\n",
       " 'use',\n",
       " 'of',\n",
       " 'anyone',\n",
       " 'anywhere',\n",
       " 'at',\n",
       " 'no',\n",
       " 'cost',\n",
       " 'and',\n",
       " 'with',\n",
       " 'almost',\n",
       " 'no',\n",
       " 'restrictions',\n",
       " 'whatsoever.',\n",
       " 'You',\n",
       " 'may',\n",
       " 'copy',\n",
       " 'it,',\n",
       " 'give',\n",
       " 'it',\n",
       " 'away',\n",
       " 'or',\n",
       " 're-use',\n",
       " 'it',\n",
       " 'under',\n",
       " 'the',\n",
       " 'terms',\n",
       " 'of',\n",
       " 'the',\n",
       " 'Project',\n",
       " 'Gutenberg',\n",
       " 'License',\n",
       " 'included',\n",
       " 'with',\n",
       " 'this',\n",
       " 'eBook',\n",
       " 'or',\n",
       " 'online',\n",
       " 'at',\n",
       " 'www.gutenberg.org',\n",
       " 'Title:',\n",
       " 'A',\n",
       " 'Journey',\n",
       " 'to',\n",
       " 'the',\n",
       " 'Centre',\n",
       " 'of',\n",
       " 'the',\n",
       " 'Earth',\n",
       " 'Author:',\n",
       " 'Jules',\n",
       " 'Verne',\n",
       " 'Release',\n",
       " 'Date:',\n",
       " 'July',\n",
       " '18,',\n",
       " '2006',\n",
       " '[EBook',\n",
       " '#18857]',\n",
       " 'Last',\n",
       " 'updated:',\n",
       " 'December',\n",
       " '27,',\n",
       " '2012',\n",
       " 'Language:',\n",
       " 'English',\n",
       " '***',\n",
       " 'START',\n",
       " 'OF',\n",
       " 'THIS',\n",
       " 'PROJECT',\n",
       " 'GUTENBERG',\n",
       " 'EBOOK',\n",
       " 'CENTRE',\n",
       " 'OF',\n",
       " 'THE',\n",
       " 'EARTH',\n",
       " '***',\n",
       " 'Produced',\n",
       " 'by',\n",
       " 'Norm',\n",
       " 'Wolcott',\n",
       " 'A',\n",
       " 'JOURNEY',\n",
       " 'TO',\n",
       " 'THE',\n",
       " 'CENTRE',\n",
       " 'OF',\n",
       " 'THE',\n",
       " 'EARTH',\n",
       " 'By',\n",
       " 'Jules',\n",
       " 'Verne',\n",
       " \"[Redactor's\",\n",
       " 'Note:',\n",
       " 'Journey',\n",
       " 'to',\n",
       " 'the',\n",
       " 'Centre',\n",
       " 'of',\n",
       " 'the',\n",
       " 'Earth',\n",
       " 'is',\n",
       " 'number',\n",
       " 'V002',\n",
       " 'in',\n",
       " 'the',\n",
       " 'Taves',\n",
       " 'and',\n",
       " 'Michaluk',\n",
       " 'numbering',\n",
       " 'of',\n",
       " 'the',\n",
       " 'works',\n",
       " 'of',\n",
       " 'Jules',\n",
       " 'Verne.',\n",
       " 'First',\n",
       " 'published',\n",
       " 'in',\n",
       " 'England',\n",
       " 'by',\n",
       " 'Griffith',\n",
       " 'and',\n",
       " 'Farran,',\n",
       " '1871,',\n",
       " 'this',\n",
       " 'edition',\n",
       " 'is',\n",
       " 'not',\n",
       " 'a',\n",
       " 'translation',\n",
       " 'at',\n",
       " 'all',\n",
       " 'but',\n",
       " 'a',\n",
       " 'complete',\n",
       " 're-write',\n",
       " 'of',\n",
       " 'the',\n",
       " 'novel,',\n",
       " 'with',\n",
       " 'portions',\n",
       " 'added',\n",
       " 'and',\n",
       " 'omitted,',\n",
       " 'and',\n",
       " 'names',\n",
       " 'changed.',\n",
       " 'The',\n",
       " 'most',\n",
       " 'reprinted',\n",
       " 'version,',\n",
       " 'it',\n",
       " 'is',\n",
       " 'entered',\n",
       " 'into',\n",
       " 'Project',\n",
       " 'Gutenberg',\n",
       " 'for',\n",
       " 'reference',\n",
       " 'purposes',\n",
       " 'only.',\n",
       " 'A',\n",
       " 'better',\n",
       " 'translation',\n",
       " 'is',\n",
       " '_A',\n",
       " 'Journey',\n",
       " 'into',\n",
       " 'the',\n",
       " 'Interior',\n",
       " 'of',\n",
       " 'the',\n",
       " 'Earth_',\n",
       " 'translated',\n",
       " 'by',\n",
       " 'Rev.',\n",
       " 'F.',\n",
       " 'A.',\n",
       " 'Malleson,',\n",
       " 'also',\n",
       " 'available',\n",
       " 'on',\n",
       " 'Project',\n",
       " 'Gutenberg.]',\n",
       " 'TABLE',\n",
       " 'OF',\n",
       " 'CONTENTS',\n",
       " 'CHAPTER',\n",
       " '1',\n",
       " 'MY',\n",
       " 'UNCLE',\n",
       " 'MAKES',\n",
       " 'A',\n",
       " 'GREAT',\n",
       " 'DISCOVERY',\n",
       " 'CHAPTER',\n",
       " '2',\n",
       " 'THE',\n",
       " 'MYSTERIOUS',\n",
       " 'PARCHMENT',\n",
       " 'CHAPTER',\n",
       " '3',\n",
       " 'AN',\n",
       " 'ASTOUNDING',\n",
       " 'DISCOVERY',\n",
       " 'CHAPTER',\n",
       " '4',\n",
       " 'WE',\n",
       " 'START',\n",
       " 'ON',\n",
       " 'THE',\n",
       " 'JOURNEY',\n",
       " 'CHAPTER',\n",
       " '5',\n",
       " 'FIRST',\n",
       " 'LESSONS',\n",
       " 'IN',\n",
       " 'CLIMBING',\n",
       " 'CHAPTER',\n",
       " '6',\n",
       " 'OUR',\n",
       " 'VOYAGE',\n",
       " 'TO',\n",
       " 'ICELAND',\n",
       " 'CHAPTER',\n",
       " '7',\n",
       " 'CONVERSATION',\n",
       " 'AND',\n",
       " 'DISCOVERY',\n",
       " 'CHAPTER',\n",
       " '8',\n",
       " 'THE',\n",
       " 'EIDER-DOWN',\n",
       " 'HUNTER--OFF',\n",
       " 'AT',\n",
       " 'LAST',\n",
       " 'CHAPTER',\n",
       " '9',\n",
       " 'OUR',\n",
       " 'START--WE',\n",
       " 'MEET',\n",
       " 'WITH',\n",
       " 'ADVENTURES',\n",
       " 'BY',\n",
       " 'THE',\n",
       " 'WAY',\n",
       " 'CHAPTER',\n",
       " '10',\n",
       " 'TRAVELING',\n",
       " 'IN',\n",
       " 'ICELAND',\n",
       " 'CHAPTER',\n",
       " '11',\n",
       " 'WE',\n",
       " 'REACH',\n",
       " 'MOUNT',\n",
       " 'SNEFFELS--THE',\n",
       " '\"REYKIR\"',\n",
       " 'CHAPTER',\n",
       " '12',\n",
       " 'THE',\n",
       " 'ASCENT',\n",
       " 'OF',\n",
       " 'MOUNT',\n",
       " 'SNEFFELS',\n",
       " 'CHAPTER',\n",
       " '13',\n",
       " 'THE',\n",
       " 'SHADOW',\n",
       " 'OF',\n",
       " 'SCARTARIS',\n",
       " 'CHAPTER',\n",
       " '14',\n",
       " 'THE',\n",
       " 'REAL',\n",
       " 'JOURNEY',\n",
       " 'COMMENCES',\n",
       " 'CHAPTER',\n",
       " '15',\n",
       " 'WE',\n",
       " 'CONTINUE',\n",
       " 'OUR',\n",
       " 'DESCENT',\n",
       " 'CHAPTER',\n",
       " '16',\n",
       " 'THE',\n",
       " 'EASTERN',\n",
       " 'TUNNEL',\n",
       " 'CHAPTER',\n",
       " '17',\n",
       " 'DEEPER',\n",
       " 'AND',\n",
       " 'DEEPER--THE',\n",
       " 'COAL',\n",
       " 'MINE',\n",
       " 'CHAPTER',\n",
       " '18',\n",
       " 'THE',\n",
       " 'WRONG',\n",
       " 'ROAD!',\n",
       " 'CHAPTER',\n",
       " '19',\n",
       " 'THE',\n",
       " 'WESTERN',\n",
       " 'GALLERY--A',\n",
       " 'NEW',\n",
       " 'ROUTE',\n",
       " 'CHAPTER',\n",
       " '20',\n",
       " 'WATER,',\n",
       " 'WHERE',\n",
       " 'IS',\n",
       " 'IT?',\n",
       " 'A',\n",
       " 'BITTER',\n",
       " 'DISAPPOINTMENT',\n",
       " 'CHAPTER',\n",
       " '21',\n",
       " 'UNDER',\n",
       " 'THE',\n",
       " 'OCEAN',\n",
       " 'CHAPTER',\n",
       " '22',\n",
       " 'SUNDAY',\n",
       " 'BELOW',\n",
       " 'GROUND',\n",
       " 'CHAPTER',\n",
       " '23',\n",
       " 'ALONE',\n",
       " 'CHAPTER',\n",
       " '24',\n",
       " 'LOST!',\n",
       " 'CHAPTER',\n",
       " '25',\n",
       " 'THE',\n",
       " 'WHISPERING',\n",
       " 'GALLERY',\n",
       " 'CHAPTER',\n",
       " '26',\n",
       " 'A',\n",
       " 'RAPID',\n",
       " 'RECOVERY',\n",
       " 'CHAPTER',\n",
       " '27',\n",
       " 'THE',\n",
       " 'CENTRAL',\n",
       " 'SEA',\n",
       " 'CHAPTER',\n",
       " '28',\n",
       " 'LAUNCHING',\n",
       " 'THE',\n",
       " 'RAFT',\n",
       " 'CHAPTER',\n",
       " '29',\n",
       " 'ON',\n",
       " 'THE',\n",
       " 'WATERS--A',\n",
       " 'RAFT',\n",
       " 'VOYAGE',\n",
       " 'CHAPTER',\n",
       " '30',\n",
       " 'TERRIFIC',\n",
       " 'SAURIAN',\n",
       " 'COMBAT',\n",
       " 'CHAPTER',\n",
       " '31',\n",
       " 'THE',\n",
       " 'SEA',\n",
       " 'MONSTER',\n",
       " 'CHAPTER',\n",
       " '32',\n",
       " 'THE',\n",
       " 'BATTLE',\n",
       " 'OF',\n",
       " 'THE',\n",
       " 'ELEMENTS',\n",
       " 'CHAPTER',\n",
       " '33',\n",
       " 'OUR',\n",
       " 'ROUTE',\n",
       " 'REVERSED',\n",
       " 'CHAPTER',\n",
       " '34',\n",
       " 'A',\n",
       " 'VOYAGE',\n",
       " 'OF',\n",
       " 'DISCOVERY',\n",
       " 'CHAPTER',\n",
       " '35',\n",
       " 'DISCOVERY',\n",
       " 'UPON',\n",
       " 'DISCOVERY',\n",
       " 'CHAPTER',\n",
       " '36',\n",
       " 'WHAT',\n",
       " 'IS',\n",
       " 'IT?',\n",
       " 'CHAPTER',\n",
       " '37',\n",
       " 'THE',\n",
       " 'MYSTERIOUS',\n",
       " 'DAGGER',\n",
       " 'CHAPTER',\n",
       " '38',\n",
       " 'NO',\n",
       " 'OUTLET--BLASTING',\n",
       " 'THE',\n",
       " 'ROCK',\n",
       " 'CHAPTER',\n",
       " '39',\n",
       " 'THE',\n",
       " 'EXPLOSION',\n",
       " 'AND',\n",
       " 'ITS',\n",
       " 'RESULTS',\n",
       " 'CHAPTER',\n",
       " '40',\n",
       " 'THE',\n",
       " 'APE',\n",
       " 'GIGANS',\n",
       " 'CHAPTER',\n",
       " '41',\n",
       " 'HUNGER',\n",
       " 'CHAPTER',\n",
       " '42',\n",
       " 'THE',\n",
       " 'VOLCANIC',\n",
       " 'SHAFT',\n",
       " 'CHAPTER',\n",
       " '43',\n",
       " 'DAYLIGHT',\n",
       " 'AT',\n",
       " 'LAST',\n",
       " 'CHAPTER',\n",
       " '44',\n",
       " 'THE',\n",
       " 'JOURNEY',\n",
       " 'ENDED',\n",
       " 'CHAPTER',\n",
       " '1',\n",
       " 'MY',\n",
       " 'UNCLE',\n",
       " 'MAKES',\n",
       " 'A',\n",
       " 'GREAT',\n",
       " 'DISCOVERY',\n",
       " 'Looking',\n",
       " 'back',\n",
       " 'to',\n",
       " 'all',\n",
       " 'that',\n",
       " 'has',\n",
       " 'occurred',\n",
       " 'to',\n",
       " 'me',\n",
       " 'since',\n",
       " 'that',\n",
       " 'eventful',\n",
       " 'day,',\n",
       " 'I',\n",
       " 'am',\n",
       " 'scarcely',\n",
       " 'able',\n",
       " 'to',\n",
       " 'believe',\n",
       " 'in',\n",
       " 'the',\n",
       " 'reality',\n",
       " 'of',\n",
       " 'my',\n",
       " 'adventures.',\n",
       " 'They',\n",
       " 'were',\n",
       " 'truly',\n",
       " 'so',\n",
       " 'wonderful',\n",
       " 'that',\n",
       " 'even',\n",
       " 'now',\n",
       " 'I',\n",
       " 'am',\n",
       " 'bewildered',\n",
       " 'when',\n",
       " 'I',\n",
       " 'think',\n",
       " 'of',\n",
       " 'them.',\n",
       " 'My',\n",
       " 'uncle',\n",
       " 'was',\n",
       " 'a',\n",
       " 'German,',\n",
       " 'having',\n",
       " 'married',\n",
       " 'my',\n",
       " \"mother's\",\n",
       " 'sister,',\n",
       " 'an',\n",
       " 'Englishwoman.',\n",
       " 'Being',\n",
       " 'very',\n",
       " 'much',\n",
       " 'attached',\n",
       " 'to',\n",
       " 'his',\n",
       " 'fatherless',\n",
       " 'nephew,',\n",
       " 'he',\n",
       " 'invited',\n",
       " 'me',\n",
       " 'to',\n",
       " 'study',\n",
       " 'under',\n",
       " 'him',\n",
       " 'in',\n",
       " 'his',\n",
       " 'home',\n",
       " 'in',\n",
       " 'the',\n",
       " 'fatherland.',\n",
       " 'This',\n",
       " 'home',\n",
       " 'was',\n",
       " 'in',\n",
       " 'a',\n",
       " 'large',\n",
       " 'town,',\n",
       " 'and',\n",
       " 'my',\n",
       " 'uncle',\n",
       " 'a',\n",
       " 'professor',\n",
       " 'of',\n",
       " 'philosophy,',\n",
       " 'chemistry,',\n",
       " 'geology,',\n",
       " 'mineralogy,',\n",
       " 'and',\n",
       " 'many',\n",
       " 'other',\n",
       " 'ologies.',\n",
       " 'One',\n",
       " 'day,',\n",
       " 'after',\n",
       " 'passing',\n",
       " 'some',\n",
       " 'hours',\n",
       " 'in',\n",
       " 'the',\n",
       " 'laboratory--my',\n",
       " 'uncle',\n",
       " 'being',\n",
       " 'absent',\n",
       " 'at',\n",
       " 'the',\n",
       " 'time--I',\n",
       " 'suddenly',\n",
       " 'felt',\n",
       " 'the',\n",
       " 'necessity',\n",
       " 'of',\n",
       " 'renovating',\n",
       " 'the',\n",
       " 'tissues--<i>i.e.</i>,',\n",
       " 'I',\n",
       " 'was',\n",
       " 'hungry,',\n",
       " 'and',\n",
       " 'was',\n",
       " 'about',\n",
       " 'to',\n",
       " 'rouse',\n",
       " 'up',\n",
       " 'our',\n",
       " 'old',\n",
       " 'French',\n",
       " 'cook,',\n",
       " 'when',\n",
       " 'my',\n",
       " 'uncle,',\n",
       " 'Professor',\n",
       " 'Von',\n",
       " 'Hardwigg,',\n",
       " 'suddenly',\n",
       " 'opened',\n",
       " 'the',\n",
       " 'street',\n",
       " 'door,',\n",
       " 'and',\n",
       " 'came',\n",
       " 'rushing',\n",
       " 'upstairs.',\n",
       " 'Now',\n",
       " 'Professor',\n",
       " 'Hardwigg,',\n",
       " 'my',\n",
       " 'worthy',\n",
       " 'uncle,',\n",
       " 'is',\n",
       " 'by',\n",
       " 'no',\n",
       " 'means',\n",
       " 'a',\n",
       " 'bad',\n",
       " 'sort',\n",
       " 'of',\n",
       " 'man;',\n",
       " 'he',\n",
       " 'is,',\n",
       " 'however,',\n",
       " 'choleric',\n",
       " 'and',\n",
       " 'original.',\n",
       " 'To',\n",
       " 'bear',\n",
       " 'with',\n",
       " 'him',\n",
       " 'means',\n",
       " 'to',\n",
       " 'obey;',\n",
       " 'and',\n",
       " 'scarcely',\n",
       " 'had',\n",
       " 'his',\n",
       " 'heavy',\n",
       " 'feet',\n",
       " 'resounded',\n",
       " 'within',\n",
       " 'our',\n",
       " 'joint',\n",
       " 'domicile',\n",
       " 'than',\n",
       " 'he',\n",
       " 'shouted',\n",
       " 'for',\n",
       " 'me',\n",
       " 'to',\n",
       " 'attend',\n",
       " 'upon',\n",
       " 'him.',\n",
       " '\"Harry--Harry--Harry--\"',\n",
       " 'I',\n",
       " 'hastened',\n",
       " 'to',\n",
       " 'obey,',\n",
       " 'but',\n",
       " 'before',\n",
       " 'I',\n",
       " 'could',\n",
       " 'reach',\n",
       " 'his',\n",
       " 'room,',\n",
       " 'jumping',\n",
       " 'three',\n",
       " 'steps',\n",
       " 'at',\n",
       " 'a',\n",
       " 'time,',\n",
       " 'he',\n",
       " 'was',\n",
       " 'stamping',\n",
       " 'his',\n",
       " 'right',\n",
       " 'foot',\n",
       " 'upon',\n",
       " 'the',\n",
       " 'landing.',\n",
       " '\"Harry!\"',\n",
       " 'he',\n",
       " 'cried,',\n",
       " 'in',\n",
       " 'a',\n",
       " 'frantic',\n",
       " 'tone,',\n",
       " '\"are',\n",
       " 'you',\n",
       " 'coming',\n",
       " 'up?\"',\n",
       " 'Now',\n",
       " 'to',\n",
       " 'tell',\n",
       " 'the',\n",
       " 'truth,',\n",
       " 'at',\n",
       " 'that',\n",
       " 'moment',\n",
       " 'I',\n",
       " 'was',\n",
       " 'far',\n",
       " 'more',\n",
       " 'interested',\n",
       " 'in',\n",
       " 'the',\n",
       " 'question',\n",
       " 'as',\n",
       " 'to',\n",
       " 'what',\n",
       " 'was',\n",
       " 'to',\n",
       " 'constitute',\n",
       " 'our',\n",
       " 'dinner',\n",
       " 'than',\n",
       " 'in',\n",
       " 'any',\n",
       " 'problem',\n",
       " 'of',\n",
       " 'science;',\n",
       " 'to',\n",
       " 'me',\n",
       " 'soup',\n",
       " 'was',\n",
       " 'more',\n",
       " 'interesting',\n",
       " 'than',\n",
       " 'soda,',\n",
       " 'an',\n",
       " 'omelette',\n",
       " 'more',\n",
       " 'tempting',\n",
       " 'than',\n",
       " 'arithmetic,',\n",
       " 'and',\n",
       " 'an',\n",
       " 'artichoke',\n",
       " 'of',\n",
       " 'ten',\n",
       " 'times',\n",
       " 'more',\n",
       " 'value',\n",
       " 'than',\n",
       " 'any',\n",
       " 'amount',\n",
       " 'of',\n",
       " 'asbestos.',\n",
       " 'But',\n",
       " 'my',\n",
       " 'uncle',\n",
       " 'was',\n",
       " 'not',\n",
       " 'a',\n",
       " 'man',\n",
       " 'to',\n",
       " 'be',\n",
       " 'kept',\n",
       " 'waiting;',\n",
       " 'so',\n",
       " 'adjourning',\n",
       " 'therefore',\n",
       " 'all',\n",
       " 'minor',\n",
       " 'questions,',\n",
       " 'I',\n",
       " 'presented',\n",
       " 'myself',\n",
       " 'before',\n",
       " 'him.',\n",
       " 'He',\n",
       " 'was',\n",
       " 'a',\n",
       " 'very',\n",
       " 'learned',\n",
       " 'man.',\n",
       " 'Now',\n",
       " 'most',\n",
       " 'persons',\n",
       " 'in',\n",
       " 'this',\n",
       " 'category',\n",
       " 'supply',\n",
       " 'themselves',\n",
       " 'with',\n",
       " 'information,',\n",
       " 'as',\n",
       " 'peddlers',\n",
       " 'do',\n",
       " 'with',\n",
       " 'goods,',\n",
       " 'for',\n",
       " 'the',\n",
       " 'benefit',\n",
       " 'of',\n",
       " 'others,',\n",
       " 'and',\n",
       " 'lay',\n",
       " 'up',\n",
       " 'stores',\n",
       " 'in',\n",
       " 'order',\n",
       " 'to',\n",
       " 'diffuse',\n",
       " 'them',\n",
       " 'abroad',\n",
       " 'for',\n",
       " 'the',\n",
       " 'benefit',\n",
       " 'of',\n",
       " 'society',\n",
       " 'in',\n",
       " 'general.',\n",
       " 'Not',\n",
       " 'so',\n",
       " 'my',\n",
       " 'excellent',\n",
       " 'uncle,',\n",
       " 'Professor',\n",
       " 'Hardwigg;',\n",
       " 'he',\n",
       " 'studied,',\n",
       " 'he',\n",
       " 'consumed',\n",
       " 'the',\n",
       " 'midnight',\n",
       " 'oil,',\n",
       " 'he',\n",
       " 'pored',\n",
       " 'over',\n",
       " 'heavy',\n",
       " 'tomes,',\n",
       " 'and',\n",
       " 'digested',\n",
       " 'huge',\n",
       " 'quartos',\n",
       " 'and',\n",
       " 'folios',\n",
       " 'in',\n",
       " 'order',\n",
       " 'to',\n",
       " 'keep',\n",
       " 'the',\n",
       " 'knowledge',\n",
       " 'acquired',\n",
       " 'to',\n",
       " 'himself.',\n",
       " 'There',\n",
       " 'was',\n",
       " 'a',\n",
       " 'reason,',\n",
       " 'and',\n",
       " 'it',\n",
       " 'may',\n",
       " 'be',\n",
       " 'regarded',\n",
       " 'as',\n",
       " 'a',\n",
       " 'good',\n",
       " 'one,',\n",
       " 'why',\n",
       " 'my',\n",
       " 'uncle',\n",
       " 'objected',\n",
       " 'to',\n",
       " 'display',\n",
       " 'his',\n",
       " 'learning',\n",
       " 'more',\n",
       " 'than',\n",
       " 'was',\n",
       " 'absolutely',\n",
       " 'necessary:',\n",
       " 'he',\n",
       " 'stammered;',\n",
       " 'and',\n",
       " 'when',\n",
       " 'intent',\n",
       " 'upon',\n",
       " 'explaining',\n",
       " 'the',\n",
       " 'phenomena',\n",
       " 'of',\n",
       " 'the',\n",
       " 'heavens,',\n",
       " 'was',\n",
       " 'apt',\n",
       " 'to',\n",
       " 'find',\n",
       " 'himself',\n",
       " 'at',\n",
       " 'fault,',\n",
       " 'and',\n",
       " 'allude',\n",
       " 'in',\n",
       " 'such',\n",
       " 'a',\n",
       " 'vague',\n",
       " 'way',\n",
       " 'to',\n",
       " 'sun,',\n",
       " 'moon,',\n",
       " 'and',\n",
       " 'stars',\n",
       " 'that',\n",
       " 'few',\n",
       " 'were',\n",
       " 'able',\n",
       " 'to',\n",
       " 'comprehend',\n",
       " 'his',\n",
       " 'meaning.',\n",
       " 'To',\n",
       " 'tell',\n",
       " 'the',\n",
       " 'honest',\n",
       " 'truth,',\n",
       " 'when',\n",
       " 'the',\n",
       " 'right',\n",
       " 'word',\n",
       " 'would',\n",
       " 'not',\n",
       " 'come,',\n",
       " 'it',\n",
       " 'was',\n",
       " 'generally',\n",
       " 'replaced',\n",
       " 'by',\n",
       " 'a',\n",
       " 'very',\n",
       " 'powerful',\n",
       " 'adjective.',\n",
       " 'In',\n",
       " 'connection',\n",
       " 'with',\n",
       " 'the',\n",
       " 'sciences',\n",
       " 'there',\n",
       " 'are',\n",
       " 'many',\n",
       " 'almost',\n",
       " 'unpronounceable',\n",
       " 'names--names',\n",
       " 'very',\n",
       " 'much',\n",
       " 'resembling',\n",
       " 'those',\n",
       " 'of',\n",
       " 'Welsh',\n",
       " 'villages;',\n",
       " 'and',\n",
       " 'my',\n",
       " 'uncle',\n",
       " 'being',\n",
       " 'very',\n",
       " 'fond',\n",
       " 'of',\n",
       " 'using',\n",
       " 'them,',\n",
       " 'his',\n",
       " 'habit',\n",
       " 'of',\n",
       " 'stammering',\n",
       " 'was',\n",
       " 'not',\n",
       " 'thereby',\n",
       " 'improved.',\n",
       " 'In',\n",
       " 'fact,',\n",
       " 'there',\n",
       " 'were',\n",
       " 'periods',\n",
       " 'in',\n",
       " 'his',\n",
       " 'discourse',\n",
       " 'when',\n",
       " 'he',\n",
       " 'would',\n",
       " 'finally',\n",
       " 'give',\n",
       " 'up',\n",
       " 'and',\n",
       " 'swallow',\n",
       " 'his',\n",
       " 'discomfiture--in',\n",
       " 'a',\n",
       " 'glass',\n",
       " 'of',\n",
       " 'water.',\n",
       " 'As',\n",
       " 'I',\n",
       " 'said,',\n",
       " 'my',\n",
       " ...]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat= data.split()\n",
    "dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data has 506332 characters, 88846 unique\n"
     ]
    }
   ],
   "source": [
    "data_size, X_size = len(data), len(dat)\n",
    "print(\"data has %d characters, %d unique\" % (data_size, X_size))\n",
    "word_to_idx = {ch:i for i,ch in enumerate(dat)}\n",
    "idx_to_word = {i:ch for i,ch in enumerate(dat)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'ï»¿Project',\n",
       " 1: \"Gutenberg's\",\n",
       " 2: 'A',\n",
       " 3: 'Journey',\n",
       " 4: 'to',\n",
       " 5: 'the',\n",
       " 6: 'Centre',\n",
       " 7: 'of',\n",
       " 8: 'the',\n",
       " 9: 'Earth,',\n",
       " 10: 'by',\n",
       " 11: 'Jules',\n",
       " 12: 'Verne',\n",
       " 13: 'This',\n",
       " 14: 'eBook',\n",
       " 15: 'is',\n",
       " 16: 'for',\n",
       " 17: 'the',\n",
       " 18: 'use',\n",
       " 19: 'of',\n",
       " 20: 'anyone',\n",
       " 21: 'anywhere',\n",
       " 22: 'at',\n",
       " 23: 'no',\n",
       " 24: 'cost',\n",
       " 25: 'and',\n",
       " 26: 'with',\n",
       " 27: 'almost',\n",
       " 28: 'no',\n",
       " 29: 'restrictions',\n",
       " 30: 'whatsoever.',\n",
       " 31: 'You',\n",
       " 32: 'may',\n",
       " 33: 'copy',\n",
       " 34: 'it,',\n",
       " 35: 'give',\n",
       " 36: 'it',\n",
       " 37: 'away',\n",
       " 38: 'or',\n",
       " 39: 're-use',\n",
       " 40: 'it',\n",
       " 41: 'under',\n",
       " 42: 'the',\n",
       " 43: 'terms',\n",
       " 44: 'of',\n",
       " 45: 'the',\n",
       " 46: 'Project',\n",
       " 47: 'Gutenberg',\n",
       " 48: 'License',\n",
       " 49: 'included',\n",
       " 50: 'with',\n",
       " 51: 'this',\n",
       " 52: 'eBook',\n",
       " 53: 'or',\n",
       " 54: 'online',\n",
       " 55: 'at',\n",
       " 56: 'www.gutenberg.org',\n",
       " 57: 'Title:',\n",
       " 58: 'A',\n",
       " 59: 'Journey',\n",
       " 60: 'to',\n",
       " 61: 'the',\n",
       " 62: 'Centre',\n",
       " 63: 'of',\n",
       " 64: 'the',\n",
       " 65: 'Earth',\n",
       " 66: 'Author:',\n",
       " 67: 'Jules',\n",
       " 68: 'Verne',\n",
       " 69: 'Release',\n",
       " 70: 'Date:',\n",
       " 71: 'July',\n",
       " 72: '18,',\n",
       " 73: '2006',\n",
       " 74: '[EBook',\n",
       " 75: '#18857]',\n",
       " 76: 'Last',\n",
       " 77: 'updated:',\n",
       " 78: 'December',\n",
       " 79: '27,',\n",
       " 80: '2012',\n",
       " 81: 'Language:',\n",
       " 82: 'English',\n",
       " 83: '***',\n",
       " 84: 'START',\n",
       " 85: 'OF',\n",
       " 86: 'THIS',\n",
       " 87: 'PROJECT',\n",
       " 88: 'GUTENBERG',\n",
       " 89: 'EBOOK',\n",
       " 90: 'CENTRE',\n",
       " 91: 'OF',\n",
       " 92: 'THE',\n",
       " 93: 'EARTH',\n",
       " 94: '***',\n",
       " 95: 'Produced',\n",
       " 96: 'by',\n",
       " 97: 'Norm',\n",
       " 98: 'Wolcott',\n",
       " 99: 'A',\n",
       " 100: 'JOURNEY',\n",
       " 101: 'TO',\n",
       " 102: 'THE',\n",
       " 103: 'CENTRE',\n",
       " 104: 'OF',\n",
       " 105: 'THE',\n",
       " 106: 'EARTH',\n",
       " 107: 'By',\n",
       " 108: 'Jules',\n",
       " 109: 'Verne',\n",
       " 110: \"[Redactor's\",\n",
       " 111: 'Note:',\n",
       " 112: 'Journey',\n",
       " 113: 'to',\n",
       " 114: 'the',\n",
       " 115: 'Centre',\n",
       " 116: 'of',\n",
       " 117: 'the',\n",
       " 118: 'Earth',\n",
       " 119: 'is',\n",
       " 120: 'number',\n",
       " 121: 'V002',\n",
       " 122: 'in',\n",
       " 123: 'the',\n",
       " 124: 'Taves',\n",
       " 125: 'and',\n",
       " 126: 'Michaluk',\n",
       " 127: 'numbering',\n",
       " 128: 'of',\n",
       " 129: 'the',\n",
       " 130: 'works',\n",
       " 131: 'of',\n",
       " 132: 'Jules',\n",
       " 133: 'Verne.',\n",
       " 134: 'First',\n",
       " 135: 'published',\n",
       " 136: 'in',\n",
       " 137: 'England',\n",
       " 138: 'by',\n",
       " 139: 'Griffith',\n",
       " 140: 'and',\n",
       " 141: 'Farran,',\n",
       " 142: '1871,',\n",
       " 143: 'this',\n",
       " 144: 'edition',\n",
       " 145: 'is',\n",
       " 146: 'not',\n",
       " 147: 'a',\n",
       " 148: 'translation',\n",
       " 149: 'at',\n",
       " 150: 'all',\n",
       " 151: 'but',\n",
       " 152: 'a',\n",
       " 153: 'complete',\n",
       " 154: 're-write',\n",
       " 155: 'of',\n",
       " 156: 'the',\n",
       " 157: 'novel,',\n",
       " 158: 'with',\n",
       " 159: 'portions',\n",
       " 160: 'added',\n",
       " 161: 'and',\n",
       " 162: 'omitted,',\n",
       " 163: 'and',\n",
       " 164: 'names',\n",
       " 165: 'changed.',\n",
       " 166: 'The',\n",
       " 167: 'most',\n",
       " 168: 'reprinted',\n",
       " 169: 'version,',\n",
       " 170: 'it',\n",
       " 171: 'is',\n",
       " 172: 'entered',\n",
       " 173: 'into',\n",
       " 174: 'Project',\n",
       " 175: 'Gutenberg',\n",
       " 176: 'for',\n",
       " 177: 'reference',\n",
       " 178: 'purposes',\n",
       " 179: 'only.',\n",
       " 180: 'A',\n",
       " 181: 'better',\n",
       " 182: 'translation',\n",
       " 183: 'is',\n",
       " 184: '_A',\n",
       " 185: 'Journey',\n",
       " 186: 'into',\n",
       " 187: 'the',\n",
       " 188: 'Interior',\n",
       " 189: 'of',\n",
       " 190: 'the',\n",
       " 191: 'Earth_',\n",
       " 192: 'translated',\n",
       " 193: 'by',\n",
       " 194: 'Rev.',\n",
       " 195: 'F.',\n",
       " 196: 'A.',\n",
       " 197: 'Malleson,',\n",
       " 198: 'also',\n",
       " 199: 'available',\n",
       " 200: 'on',\n",
       " 201: 'Project',\n",
       " 202: 'Gutenberg.]',\n",
       " 203: 'TABLE',\n",
       " 204: 'OF',\n",
       " 205: 'CONTENTS',\n",
       " 206: 'CHAPTER',\n",
       " 207: '1',\n",
       " 208: 'MY',\n",
       " 209: 'UNCLE',\n",
       " 210: 'MAKES',\n",
       " 211: 'A',\n",
       " 212: 'GREAT',\n",
       " 213: 'DISCOVERY',\n",
       " 214: 'CHAPTER',\n",
       " 215: '2',\n",
       " 216: 'THE',\n",
       " 217: 'MYSTERIOUS',\n",
       " 218: 'PARCHMENT',\n",
       " 219: 'CHAPTER',\n",
       " 220: '3',\n",
       " 221: 'AN',\n",
       " 222: 'ASTOUNDING',\n",
       " 223: 'DISCOVERY',\n",
       " 224: 'CHAPTER',\n",
       " 225: '4',\n",
       " 226: 'WE',\n",
       " 227: 'START',\n",
       " 228: 'ON',\n",
       " 229: 'THE',\n",
       " 230: 'JOURNEY',\n",
       " 231: 'CHAPTER',\n",
       " 232: '5',\n",
       " 233: 'FIRST',\n",
       " 234: 'LESSONS',\n",
       " 235: 'IN',\n",
       " 236: 'CLIMBING',\n",
       " 237: 'CHAPTER',\n",
       " 238: '6',\n",
       " 239: 'OUR',\n",
       " 240: 'VOYAGE',\n",
       " 241: 'TO',\n",
       " 242: 'ICELAND',\n",
       " 243: 'CHAPTER',\n",
       " 244: '7',\n",
       " 245: 'CONVERSATION',\n",
       " 246: 'AND',\n",
       " 247: 'DISCOVERY',\n",
       " 248: 'CHAPTER',\n",
       " 249: '8',\n",
       " 250: 'THE',\n",
       " 251: 'EIDER-DOWN',\n",
       " 252: 'HUNTER--OFF',\n",
       " 253: 'AT',\n",
       " 254: 'LAST',\n",
       " 255: 'CHAPTER',\n",
       " 256: '9',\n",
       " 257: 'OUR',\n",
       " 258: 'START--WE',\n",
       " 259: 'MEET',\n",
       " 260: 'WITH',\n",
       " 261: 'ADVENTURES',\n",
       " 262: 'BY',\n",
       " 263: 'THE',\n",
       " 264: 'WAY',\n",
       " 265: 'CHAPTER',\n",
       " 266: '10',\n",
       " 267: 'TRAVELING',\n",
       " 268: 'IN',\n",
       " 269: 'ICELAND',\n",
       " 270: 'CHAPTER',\n",
       " 271: '11',\n",
       " 272: 'WE',\n",
       " 273: 'REACH',\n",
       " 274: 'MOUNT',\n",
       " 275: 'SNEFFELS--THE',\n",
       " 276: '\"REYKIR\"',\n",
       " 277: 'CHAPTER',\n",
       " 278: '12',\n",
       " 279: 'THE',\n",
       " 280: 'ASCENT',\n",
       " 281: 'OF',\n",
       " 282: 'MOUNT',\n",
       " 283: 'SNEFFELS',\n",
       " 284: 'CHAPTER',\n",
       " 285: '13',\n",
       " 286: 'THE',\n",
       " 287: 'SHADOW',\n",
       " 288: 'OF',\n",
       " 289: 'SCARTARIS',\n",
       " 290: 'CHAPTER',\n",
       " 291: '14',\n",
       " 292: 'THE',\n",
       " 293: 'REAL',\n",
       " 294: 'JOURNEY',\n",
       " 295: 'COMMENCES',\n",
       " 296: 'CHAPTER',\n",
       " 297: '15',\n",
       " 298: 'WE',\n",
       " 299: 'CONTINUE',\n",
       " 300: 'OUR',\n",
       " 301: 'DESCENT',\n",
       " 302: 'CHAPTER',\n",
       " 303: '16',\n",
       " 304: 'THE',\n",
       " 305: 'EASTERN',\n",
       " 306: 'TUNNEL',\n",
       " 307: 'CHAPTER',\n",
       " 308: '17',\n",
       " 309: 'DEEPER',\n",
       " 310: 'AND',\n",
       " 311: 'DEEPER--THE',\n",
       " 312: 'COAL',\n",
       " 313: 'MINE',\n",
       " 314: 'CHAPTER',\n",
       " 315: '18',\n",
       " 316: 'THE',\n",
       " 317: 'WRONG',\n",
       " 318: 'ROAD!',\n",
       " 319: 'CHAPTER',\n",
       " 320: '19',\n",
       " 321: 'THE',\n",
       " 322: 'WESTERN',\n",
       " 323: 'GALLERY--A',\n",
       " 324: 'NEW',\n",
       " 325: 'ROUTE',\n",
       " 326: 'CHAPTER',\n",
       " 327: '20',\n",
       " 328: 'WATER,',\n",
       " 329: 'WHERE',\n",
       " 330: 'IS',\n",
       " 331: 'IT?',\n",
       " 332: 'A',\n",
       " 333: 'BITTER',\n",
       " 334: 'DISAPPOINTMENT',\n",
       " 335: 'CHAPTER',\n",
       " 336: '21',\n",
       " 337: 'UNDER',\n",
       " 338: 'THE',\n",
       " 339: 'OCEAN',\n",
       " 340: 'CHAPTER',\n",
       " 341: '22',\n",
       " 342: 'SUNDAY',\n",
       " 343: 'BELOW',\n",
       " 344: 'GROUND',\n",
       " 345: 'CHAPTER',\n",
       " 346: '23',\n",
       " 347: 'ALONE',\n",
       " 348: 'CHAPTER',\n",
       " 349: '24',\n",
       " 350: 'LOST!',\n",
       " 351: 'CHAPTER',\n",
       " 352: '25',\n",
       " 353: 'THE',\n",
       " 354: 'WHISPERING',\n",
       " 355: 'GALLERY',\n",
       " 356: 'CHAPTER',\n",
       " 357: '26',\n",
       " 358: 'A',\n",
       " 359: 'RAPID',\n",
       " 360: 'RECOVERY',\n",
       " 361: 'CHAPTER',\n",
       " 362: '27',\n",
       " 363: 'THE',\n",
       " 364: 'CENTRAL',\n",
       " 365: 'SEA',\n",
       " 366: 'CHAPTER',\n",
       " 367: '28',\n",
       " 368: 'LAUNCHING',\n",
       " 369: 'THE',\n",
       " 370: 'RAFT',\n",
       " 371: 'CHAPTER',\n",
       " 372: '29',\n",
       " 373: 'ON',\n",
       " 374: 'THE',\n",
       " 375: 'WATERS--A',\n",
       " 376: 'RAFT',\n",
       " 377: 'VOYAGE',\n",
       " 378: 'CHAPTER',\n",
       " 379: '30',\n",
       " 380: 'TERRIFIC',\n",
       " 381: 'SAURIAN',\n",
       " 382: 'COMBAT',\n",
       " 383: 'CHAPTER',\n",
       " 384: '31',\n",
       " 385: 'THE',\n",
       " 386: 'SEA',\n",
       " 387: 'MONSTER',\n",
       " 388: 'CHAPTER',\n",
       " 389: '32',\n",
       " 390: 'THE',\n",
       " 391: 'BATTLE',\n",
       " 392: 'OF',\n",
       " 393: 'THE',\n",
       " 394: 'ELEMENTS',\n",
       " 395: 'CHAPTER',\n",
       " 396: '33',\n",
       " 397: 'OUR',\n",
       " 398: 'ROUTE',\n",
       " 399: 'REVERSED',\n",
       " 400: 'CHAPTER',\n",
       " 401: '34',\n",
       " 402: 'A',\n",
       " 403: 'VOYAGE',\n",
       " 404: 'OF',\n",
       " 405: 'DISCOVERY',\n",
       " 406: 'CHAPTER',\n",
       " 407: '35',\n",
       " 408: 'DISCOVERY',\n",
       " 409: 'UPON',\n",
       " 410: 'DISCOVERY',\n",
       " 411: 'CHAPTER',\n",
       " 412: '36',\n",
       " 413: 'WHAT',\n",
       " 414: 'IS',\n",
       " 415: 'IT?',\n",
       " 416: 'CHAPTER',\n",
       " 417: '37',\n",
       " 418: 'THE',\n",
       " 419: 'MYSTERIOUS',\n",
       " 420: 'DAGGER',\n",
       " 421: 'CHAPTER',\n",
       " 422: '38',\n",
       " 423: 'NO',\n",
       " 424: 'OUTLET--BLASTING',\n",
       " 425: 'THE',\n",
       " 426: 'ROCK',\n",
       " 427: 'CHAPTER',\n",
       " 428: '39',\n",
       " 429: 'THE',\n",
       " 430: 'EXPLOSION',\n",
       " 431: 'AND',\n",
       " 432: 'ITS',\n",
       " 433: 'RESULTS',\n",
       " 434: 'CHAPTER',\n",
       " 435: '40',\n",
       " 436: 'THE',\n",
       " 437: 'APE',\n",
       " 438: 'GIGANS',\n",
       " 439: 'CHAPTER',\n",
       " 440: '41',\n",
       " 441: 'HUNGER',\n",
       " 442: 'CHAPTER',\n",
       " 443: '42',\n",
       " 444: 'THE',\n",
       " 445: 'VOLCANIC',\n",
       " 446: 'SHAFT',\n",
       " 447: 'CHAPTER',\n",
       " 448: '43',\n",
       " 449: 'DAYLIGHT',\n",
       " 450: 'AT',\n",
       " 451: 'LAST',\n",
       " 452: 'CHAPTER',\n",
       " 453: '44',\n",
       " 454: 'THE',\n",
       " 455: 'JOURNEY',\n",
       " 456: 'ENDED',\n",
       " 457: 'CHAPTER',\n",
       " 458: '1',\n",
       " 459: 'MY',\n",
       " 460: 'UNCLE',\n",
       " 461: 'MAKES',\n",
       " 462: 'A',\n",
       " 463: 'GREAT',\n",
       " 464: 'DISCOVERY',\n",
       " 465: 'Looking',\n",
       " 466: 'back',\n",
       " 467: 'to',\n",
       " 468: 'all',\n",
       " 469: 'that',\n",
       " 470: 'has',\n",
       " 471: 'occurred',\n",
       " 472: 'to',\n",
       " 473: 'me',\n",
       " 474: 'since',\n",
       " 475: 'that',\n",
       " 476: 'eventful',\n",
       " 477: 'day,',\n",
       " 478: 'I',\n",
       " 479: 'am',\n",
       " 480: 'scarcely',\n",
       " 481: 'able',\n",
       " 482: 'to',\n",
       " 483: 'believe',\n",
       " 484: 'in',\n",
       " 485: 'the',\n",
       " 486: 'reality',\n",
       " 487: 'of',\n",
       " 488: 'my',\n",
       " 489: 'adventures.',\n",
       " 490: 'They',\n",
       " 491: 'were',\n",
       " 492: 'truly',\n",
       " 493: 'so',\n",
       " 494: 'wonderful',\n",
       " 495: 'that',\n",
       " 496: 'even',\n",
       " 497: 'now',\n",
       " 498: 'I',\n",
       " 499: 'am',\n",
       " 500: 'bewildered',\n",
       " 501: 'when',\n",
       " 502: 'I',\n",
       " 503: 'think',\n",
       " 504: 'of',\n",
       " 505: 'them.',\n",
       " 506: 'My',\n",
       " 507: 'uncle',\n",
       " 508: 'was',\n",
       " 509: 'a',\n",
       " 510: 'German,',\n",
       " 511: 'having',\n",
       " 512: 'married',\n",
       " 513: 'my',\n",
       " 514: \"mother's\",\n",
       " 515: 'sister,',\n",
       " 516: 'an',\n",
       " 517: 'Englishwoman.',\n",
       " 518: 'Being',\n",
       " 519: 'very',\n",
       " 520: 'much',\n",
       " 521: 'attached',\n",
       " 522: 'to',\n",
       " 523: 'his',\n",
       " 524: 'fatherless',\n",
       " 525: 'nephew,',\n",
       " 526: 'he',\n",
       " 527: 'invited',\n",
       " 528: 'me',\n",
       " 529: 'to',\n",
       " 530: 'study',\n",
       " 531: 'under',\n",
       " 532: 'him',\n",
       " 533: 'in',\n",
       " 534: 'his',\n",
       " 535: 'home',\n",
       " 536: 'in',\n",
       " 537: 'the',\n",
       " 538: 'fatherland.',\n",
       " 539: 'This',\n",
       " 540: 'home',\n",
       " 541: 'was',\n",
       " 542: 'in',\n",
       " 543: 'a',\n",
       " 544: 'large',\n",
       " 545: 'town,',\n",
       " 546: 'and',\n",
       " 547: 'my',\n",
       " 548: 'uncle',\n",
       " 549: 'a',\n",
       " 550: 'professor',\n",
       " 551: 'of',\n",
       " 552: 'philosophy,',\n",
       " 553: 'chemistry,',\n",
       " 554: 'geology,',\n",
       " 555: 'mineralogy,',\n",
       " 556: 'and',\n",
       " 557: 'many',\n",
       " 558: 'other',\n",
       " 559: 'ologies.',\n",
       " 560: 'One',\n",
       " 561: 'day,',\n",
       " 562: 'after',\n",
       " 563: 'passing',\n",
       " 564: 'some',\n",
       " 565: 'hours',\n",
       " 566: 'in',\n",
       " 567: 'the',\n",
       " 568: 'laboratory--my',\n",
       " 569: 'uncle',\n",
       " 570: 'being',\n",
       " 571: 'absent',\n",
       " 572: 'at',\n",
       " 573: 'the',\n",
       " 574: 'time--I',\n",
       " 575: 'suddenly',\n",
       " 576: 'felt',\n",
       " 577: 'the',\n",
       " 578: 'necessity',\n",
       " 579: 'of',\n",
       " 580: 'renovating',\n",
       " 581: 'the',\n",
       " 582: 'tissues--<i>i.e.</i>,',\n",
       " 583: 'I',\n",
       " 584: 'was',\n",
       " 585: 'hungry,',\n",
       " 586: 'and',\n",
       " 587: 'was',\n",
       " 588: 'about',\n",
       " 589: 'to',\n",
       " 590: 'rouse',\n",
       " 591: 'up',\n",
       " 592: 'our',\n",
       " 593: 'old',\n",
       " 594: 'French',\n",
       " 595: 'cook,',\n",
       " 596: 'when',\n",
       " 597: 'my',\n",
       " 598: 'uncle,',\n",
       " 599: 'Professor',\n",
       " 600: 'Von',\n",
       " 601: 'Hardwigg,',\n",
       " 602: 'suddenly',\n",
       " 603: 'opened',\n",
       " 604: 'the',\n",
       " 605: 'street',\n",
       " 606: 'door,',\n",
       " 607: 'and',\n",
       " 608: 'came',\n",
       " 609: 'rushing',\n",
       " 610: 'upstairs.',\n",
       " 611: 'Now',\n",
       " 612: 'Professor',\n",
       " 613: 'Hardwigg,',\n",
       " 614: 'my',\n",
       " 615: 'worthy',\n",
       " 616: 'uncle,',\n",
       " 617: 'is',\n",
       " 618: 'by',\n",
       " 619: 'no',\n",
       " 620: 'means',\n",
       " 621: 'a',\n",
       " 622: 'bad',\n",
       " 623: 'sort',\n",
       " 624: 'of',\n",
       " 625: 'man;',\n",
       " 626: 'he',\n",
       " 627: 'is,',\n",
       " 628: 'however,',\n",
       " 629: 'choleric',\n",
       " 630: 'and',\n",
       " 631: 'original.',\n",
       " 632: 'To',\n",
       " 633: 'bear',\n",
       " 634: 'with',\n",
       " 635: 'him',\n",
       " 636: 'means',\n",
       " 637: 'to',\n",
       " 638: 'obey;',\n",
       " 639: 'and',\n",
       " 640: 'scarcely',\n",
       " 641: 'had',\n",
       " 642: 'his',\n",
       " 643: 'heavy',\n",
       " 644: 'feet',\n",
       " 645: 'resounded',\n",
       " 646: 'within',\n",
       " 647: 'our',\n",
       " 648: 'joint',\n",
       " 649: 'domicile',\n",
       " 650: 'than',\n",
       " 651: 'he',\n",
       " 652: 'shouted',\n",
       " 653: 'for',\n",
       " 654: 'me',\n",
       " 655: 'to',\n",
       " 656: 'attend',\n",
       " 657: 'upon',\n",
       " 658: 'him.',\n",
       " 659: '\"Harry--Harry--Harry--\"',\n",
       " 660: 'I',\n",
       " 661: 'hastened',\n",
       " 662: 'to',\n",
       " 663: 'obey,',\n",
       " 664: 'but',\n",
       " 665: 'before',\n",
       " 666: 'I',\n",
       " 667: 'could',\n",
       " 668: 'reach',\n",
       " 669: 'his',\n",
       " 670: 'room,',\n",
       " 671: 'jumping',\n",
       " 672: 'three',\n",
       " 673: 'steps',\n",
       " 674: 'at',\n",
       " 675: 'a',\n",
       " 676: 'time,',\n",
       " 677: 'he',\n",
       " 678: 'was',\n",
       " 679: 'stamping',\n",
       " 680: 'his',\n",
       " 681: 'right',\n",
       " 682: 'foot',\n",
       " 683: 'upon',\n",
       " 684: 'the',\n",
       " 685: 'landing.',\n",
       " 686: '\"Harry!\"',\n",
       " 687: 'he',\n",
       " 688: 'cried,',\n",
       " 689: 'in',\n",
       " 690: 'a',\n",
       " 691: 'frantic',\n",
       " 692: 'tone,',\n",
       " 693: '\"are',\n",
       " 694: 'you',\n",
       " 695: 'coming',\n",
       " 696: 'up?\"',\n",
       " 697: 'Now',\n",
       " 698: 'to',\n",
       " 699: 'tell',\n",
       " 700: 'the',\n",
       " 701: 'truth,',\n",
       " 702: 'at',\n",
       " 703: 'that',\n",
       " 704: 'moment',\n",
       " 705: 'I',\n",
       " 706: 'was',\n",
       " 707: 'far',\n",
       " 708: 'more',\n",
       " 709: 'interested',\n",
       " 710: 'in',\n",
       " 711: 'the',\n",
       " 712: 'question',\n",
       " 713: 'as',\n",
       " 714: 'to',\n",
       " 715: 'what',\n",
       " 716: 'was',\n",
       " 717: 'to',\n",
       " 718: 'constitute',\n",
       " 719: 'our',\n",
       " 720: 'dinner',\n",
       " 721: 'than',\n",
       " 722: 'in',\n",
       " 723: 'any',\n",
       " 724: 'problem',\n",
       " 725: 'of',\n",
       " 726: 'science;',\n",
       " 727: 'to',\n",
       " 728: 'me',\n",
       " 729: 'soup',\n",
       " 730: 'was',\n",
       " 731: 'more',\n",
       " 732: 'interesting',\n",
       " 733: 'than',\n",
       " 734: 'soda,',\n",
       " 735: 'an',\n",
       " 736: 'omelette',\n",
       " 737: 'more',\n",
       " 738: 'tempting',\n",
       " 739: 'than',\n",
       " 740: 'arithmetic,',\n",
       " 741: 'and',\n",
       " 742: 'an',\n",
       " 743: 'artichoke',\n",
       " 744: 'of',\n",
       " 745: 'ten',\n",
       " 746: 'times',\n",
       " 747: 'more',\n",
       " 748: 'value',\n",
       " 749: 'than',\n",
       " 750: 'any',\n",
       " 751: 'amount',\n",
       " 752: 'of',\n",
       " 753: 'asbestos.',\n",
       " 754: 'But',\n",
       " 755: 'my',\n",
       " 756: 'uncle',\n",
       " 757: 'was',\n",
       " 758: 'not',\n",
       " 759: 'a',\n",
       " 760: 'man',\n",
       " 761: 'to',\n",
       " 762: 'be',\n",
       " 763: 'kept',\n",
       " 764: 'waiting;',\n",
       " 765: 'so',\n",
       " 766: 'adjourning',\n",
       " 767: 'therefore',\n",
       " 768: 'all',\n",
       " 769: 'minor',\n",
       " 770: 'questions,',\n",
       " 771: 'I',\n",
       " 772: 'presented',\n",
       " 773: 'myself',\n",
       " 774: 'before',\n",
       " 775: 'him.',\n",
       " 776: 'He',\n",
       " 777: 'was',\n",
       " 778: 'a',\n",
       " 779: 'very',\n",
       " 780: 'learned',\n",
       " 781: 'man.',\n",
       " 782: 'Now',\n",
       " 783: 'most',\n",
       " 784: 'persons',\n",
       " 785: 'in',\n",
       " 786: 'this',\n",
       " 787: 'category',\n",
       " 788: 'supply',\n",
       " 789: 'themselves',\n",
       " 790: 'with',\n",
       " 791: 'information,',\n",
       " 792: 'as',\n",
       " 793: 'peddlers',\n",
       " 794: 'do',\n",
       " 795: 'with',\n",
       " 796: 'goods,',\n",
       " 797: 'for',\n",
       " 798: 'the',\n",
       " 799: 'benefit',\n",
       " 800: 'of',\n",
       " 801: 'others,',\n",
       " 802: 'and',\n",
       " 803: 'lay',\n",
       " 804: 'up',\n",
       " 805: 'stores',\n",
       " 806: 'in',\n",
       " 807: 'order',\n",
       " 808: 'to',\n",
       " 809: 'diffuse',\n",
       " 810: 'them',\n",
       " 811: 'abroad',\n",
       " 812: 'for',\n",
       " 813: 'the',\n",
       " 814: 'benefit',\n",
       " 815: 'of',\n",
       " 816: 'society',\n",
       " 817: 'in',\n",
       " 818: 'general.',\n",
       " 819: 'Not',\n",
       " 820: 'so',\n",
       " 821: 'my',\n",
       " 822: 'excellent',\n",
       " 823: 'uncle,',\n",
       " 824: 'Professor',\n",
       " 825: 'Hardwigg;',\n",
       " 826: 'he',\n",
       " 827: 'studied,',\n",
       " 828: 'he',\n",
       " 829: 'consumed',\n",
       " 830: 'the',\n",
       " 831: 'midnight',\n",
       " 832: 'oil,',\n",
       " 833: 'he',\n",
       " 834: 'pored',\n",
       " 835: 'over',\n",
       " 836: 'heavy',\n",
       " 837: 'tomes,',\n",
       " 838: 'and',\n",
       " 839: 'digested',\n",
       " 840: 'huge',\n",
       " 841: 'quartos',\n",
       " 842: 'and',\n",
       " 843: 'folios',\n",
       " 844: 'in',\n",
       " 845: 'order',\n",
       " 846: 'to',\n",
       " 847: 'keep',\n",
       " 848: 'the',\n",
       " 849: 'knowledge',\n",
       " 850: 'acquired',\n",
       " 851: 'to',\n",
       " 852: 'himself.',\n",
       " 853: 'There',\n",
       " 854: 'was',\n",
       " 855: 'a',\n",
       " 856: 'reason,',\n",
       " 857: 'and',\n",
       " 858: 'it',\n",
       " 859: 'may',\n",
       " 860: 'be',\n",
       " 861: 'regarded',\n",
       " 862: 'as',\n",
       " 863: 'a',\n",
       " 864: 'good',\n",
       " 865: 'one,',\n",
       " 866: 'why',\n",
       " 867: 'my',\n",
       " 868: 'uncle',\n",
       " 869: 'objected',\n",
       " 870: 'to',\n",
       " 871: 'display',\n",
       " 872: 'his',\n",
       " 873: 'learning',\n",
       " 874: 'more',\n",
       " 875: 'than',\n",
       " 876: 'was',\n",
       " 877: 'absolutely',\n",
       " 878: 'necessary:',\n",
       " 879: 'he',\n",
       " 880: 'stammered;',\n",
       " 881: 'and',\n",
       " 882: 'when',\n",
       " 883: 'intent',\n",
       " 884: 'upon',\n",
       " 885: 'explaining',\n",
       " 886: 'the',\n",
       " 887: 'phenomena',\n",
       " 888: 'of',\n",
       " 889: 'the',\n",
       " 890: 'heavens,',\n",
       " 891: 'was',\n",
       " 892: 'apt',\n",
       " 893: 'to',\n",
       " 894: 'find',\n",
       " 895: 'himself',\n",
       " 896: 'at',\n",
       " 897: 'fault,',\n",
       " 898: 'and',\n",
       " 899: 'allude',\n",
       " 900: 'in',\n",
       " 901: 'such',\n",
       " 902: 'a',\n",
       " 903: 'vague',\n",
       " 904: 'way',\n",
       " 905: 'to',\n",
       " 906: 'sun,',\n",
       " 907: 'moon,',\n",
       " 908: 'and',\n",
       " 909: 'stars',\n",
       " 910: 'that',\n",
       " 911: 'few',\n",
       " 912: 'were',\n",
       " 913: 'able',\n",
       " 914: 'to',\n",
       " 915: 'comprehend',\n",
       " 916: 'his',\n",
       " 917: 'meaning.',\n",
       " 918: 'To',\n",
       " 919: 'tell',\n",
       " 920: 'the',\n",
       " 921: 'honest',\n",
       " 922: 'truth,',\n",
       " 923: 'when',\n",
       " 924: 'the',\n",
       " 925: 'right',\n",
       " 926: 'word',\n",
       " 927: 'would',\n",
       " 928: 'not',\n",
       " 929: 'come,',\n",
       " 930: 'it',\n",
       " 931: 'was',\n",
       " 932: 'generally',\n",
       " 933: 'replaced',\n",
       " 934: 'by',\n",
       " 935: 'a',\n",
       " 936: 'very',\n",
       " 937: 'powerful',\n",
       " 938: 'adjective.',\n",
       " 939: 'In',\n",
       " 940: 'connection',\n",
       " 941: 'with',\n",
       " 942: 'the',\n",
       " 943: 'sciences',\n",
       " 944: 'there',\n",
       " 945: 'are',\n",
       " 946: 'many',\n",
       " 947: 'almost',\n",
       " 948: 'unpronounceable',\n",
       " 949: 'names--names',\n",
       " 950: 'very',\n",
       " 951: 'much',\n",
       " 952: 'resembling',\n",
       " 953: 'those',\n",
       " 954: 'of',\n",
       " 955: 'Welsh',\n",
       " 956: 'villages;',\n",
       " 957: 'and',\n",
       " 958: 'my',\n",
       " 959: 'uncle',\n",
       " 960: 'being',\n",
       " 961: 'very',\n",
       " 962: 'fond',\n",
       " 963: 'of',\n",
       " 964: 'using',\n",
       " 965: 'them,',\n",
       " 966: 'his',\n",
       " 967: 'habit',\n",
       " 968: 'of',\n",
       " 969: 'stammering',\n",
       " 970: 'was',\n",
       " 971: 'not',\n",
       " 972: 'thereby',\n",
       " 973: 'improved.',\n",
       " 974: 'In',\n",
       " 975: 'fact,',\n",
       " 976: 'there',\n",
       " 977: 'were',\n",
       " 978: 'periods',\n",
       " 979: 'in',\n",
       " 980: 'his',\n",
       " 981: 'discourse',\n",
       " 982: 'when',\n",
       " 983: 'he',\n",
       " 984: 'would',\n",
       " 985: 'finally',\n",
       " 986: 'give',\n",
       " 987: 'up',\n",
       " 988: 'and',\n",
       " 989: 'swallow',\n",
       " 990: 'his',\n",
       " 991: 'discomfiture--in',\n",
       " 992: 'a',\n",
       " 993: 'glass',\n",
       " 994: 'of',\n",
       " 995: 'water.',\n",
       " 996: 'As',\n",
       " 997: 'I',\n",
       " 998: 'said,',\n",
       " 999: 'my',\n",
       " ...}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_to_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Constants and hyper-params\n",
    "H_size = 100 # Size of the hidden layer\n",
    "T_steps = 25 # Number of time steps (length of the sequence) used for training\n",
    "learning_rate = 1e-1 # Learning rate\n",
    "weight_sd = 0.1 # Standard deviation of weights for initialization\n",
    "z_size = H_size + X_size # Size of concatenate(H, X) vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing parameters \n",
    "\n",
    "# Constants and hyper-params\n",
    "H_size = 100 # Size of the hidden layer\n",
    "T_steps = 13 # Number of time steps (length of the sequence) used for training\n",
    "learning_rate = 1e-1 # Learning rate\n",
    "weight_sd = 0.1 # Standard deviation of weights for initialization\n",
    "z_size = H_size + X_size # Size of concatenate(H, X) vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "\n",
    "def dsigmoid(y):\n",
    "    return y * (1 - y)\n",
    "\n",
    "\n",
    "def tanh(x):\n",
    "    return np.tanh(x)\n",
    "\n",
    "\n",
    "def dtanh(y):\n",
    "    return 1 - y * y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5107"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc \n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "# We use random weights with normal distribution (0, weight_sd) for  tanh  activation function \n",
    "# and (0.5, weight_sd) for  sigmoid  activation function.\n",
    "# Biases are initialized to zeros.\n",
    "class Param:\n",
    "    def __init__(self, name, value):\n",
    "        self.name = name\n",
    "        self.v = value #parameter value\n",
    "        self.d = np.zeros_like(value) #derivative\n",
    "        self.m = np.zeros_like(value) #momentum for AdaGrad\n",
    "        \n",
    "class Parameters:\n",
    "    def __init__(self):\n",
    "        self.W_f = Param('W_f', \n",
    "                         np.random.randn(H_size, z_size) * weight_sd + 0.5)\n",
    "        self.b_f = Param('b_f',\n",
    "                         np.zeros((H_size, 1)))\n",
    "\n",
    "        self.W_i = Param('W_i',\n",
    "                         np.random.randn(H_size, z_size) * weight_sd + 0.5)\n",
    "        self.b_i = Param('b_i',\n",
    "                         np.zeros((H_size, 1)))\n",
    "\n",
    "        self.W_C = Param('W_C',\n",
    "                         np.random.randn(H_size, z_size) * weight_sd)\n",
    "        self.b_C = Param('b_C',\n",
    "                         np.zeros((H_size, 1)))\n",
    "\n",
    "        self.W_o = Param('W_o',\n",
    "                         np.random.randn(H_size, z_size) * weight_sd + 0.5)\n",
    "        self.b_o = Param('b_o',\n",
    "                         np.zeros((H_size, 1)))\n",
    "\n",
    "        #For final layer to predict the next character\n",
    "        self.W_v = Param('W_v',\n",
    "                         np.random.randn(X_size, H_size) * weight_sd)\n",
    "        self.b_v = Param('b_v',\n",
    "                         np.zeros((X_size, 1)))\n",
    "        \n",
    "    def all(self):\n",
    "        return [self.W_f, self.W_i, self.W_C, self.W_o, self.W_v,\n",
    "               self.b_f, self.b_i, self.b_C, self.b_o, self.b_v]\n",
    "        \n",
    "parameters = Parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(x, h_prev, C_prev, p = parameters):\n",
    "    assert x.shape == (X_size, 1)\n",
    "    assert h_prev.shape == (H_size, 1)\n",
    "    assert C_prev.shape == (H_size, 1)\n",
    "    \n",
    "    z = np.row_stack((h_prev, x))\n",
    "    f = sigmoid(np.dot(p.W_f.v, z) + p.b_f.v)\n",
    "    i = sigmoid(np.dot(p.W_i.v, z) + p.b_i.v)\n",
    "    C_bar = tanh(np.dot(p.W_C.v, z) + p.b_C.v)\n",
    "\n",
    "    C = f * C_prev + i * C_bar\n",
    "    o = sigmoid(np.dot(p.W_o.v, z) + p.b_o.v)\n",
    "    h = o * tanh(C)\n",
    "\n",
    "    v = np.dot(p.W_v.v, h) + p.b_v.v\n",
    "    y = np.exp(v) / np.sum(np.exp(v)) #softmax\n",
    "\n",
    "    return z, f, i, C_bar, C, o, h, v, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummyVector = np.random.randn(10, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.97428392],\n",
       "       [-0.80404186],\n",
       "       [-0.1445241 ],\n",
       "       [ 0.42658502],\n",
       "       [-1.26027756],\n",
       "       [-0.39094084],\n",
       "       [-0.3368273 ],\n",
       "       [ 1.48988489],\n",
       "       [ 0.8255934 ],\n",
       "       [-0.88608436]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummyVector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.27402745],\n",
       "       [0.30916159],\n",
       "       [0.46393173],\n",
       "       [0.60505791],\n",
       "       [0.22092612],\n",
       "       [0.40349083],\n",
       "       [0.41658037],\n",
       "       [0.81606099],\n",
       "       [0.69542237],\n",
       "       [0.29191854]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid(dummyVector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward(target, dh_next, dC_next, C_prev,\n",
    "             z, f, i, C_bar, C, o, h, v, y,\n",
    "             p = parameters):\n",
    "    \n",
    "    assert z.shape == (X_size + H_size, 1)\n",
    "    assert v.shape == (X_size, 1)\n",
    "    assert y.shape == (X_size, 1)\n",
    "    \n",
    "    for param in [dh_next, dC_next, C_prev, f, i, C_bar, C, o, h]:\n",
    "        assert param.shape == (H_size, 1)\n",
    "        \n",
    "    dv = np.copy(y)\n",
    "    dv[target] -= 1\n",
    "\n",
    "    p.W_v.d += np.dot(dv, h.T)\n",
    "    p.b_v.d += dv\n",
    "\n",
    "    dh = np.dot(p.W_v.v.T, dv)        \n",
    "    dh += dh_next\n",
    "    do = dh * tanh(C)\n",
    "    do = dsigmoid(o) * do\n",
    "    p.W_o.d += np.dot(do, z.T)\n",
    "    p.b_o.d += do\n",
    "\n",
    "    dC = np.copy(dC_next)\n",
    "    dC += dh * o * dtanh(tanh(C))\n",
    "    dC_bar = dC * i\n",
    "    dC_bar = dtanh(C_bar) * dC_bar\n",
    "    p.W_C.d += np.dot(dC_bar, z.T)\n",
    "    p.b_C.d += dC_bar\n",
    "\n",
    "    di = dC * C_bar\n",
    "    di = dsigmoid(i) * di\n",
    "    p.W_i.d += np.dot(di, z.T)\n",
    "    p.b_i.d += di\n",
    "\n",
    "    df = dC * C_prev\n",
    "    df = dsigmoid(f) * df\n",
    "    p.W_f.d += np.dot(df, z.T)\n",
    "    p.b_f.d += df\n",
    "\n",
    "    dz = (np.dot(p.W_f.v.T, df)\n",
    "         + np.dot(p.W_i.v.T, di)\n",
    "         + np.dot(p.W_C.v.T, dC_bar)\n",
    "         + np.dot(p.W_o.v.T, do))\n",
    "    dh_prev = dz[:H_size, :]\n",
    "    dC_prev = f * dC\n",
    "    \n",
    "    return dh_prev, dC_prev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear gradients before each backward pass\n",
    "def clear_gradients(params = parameters):\n",
    "    for p in params.all():\n",
    "        p.d.fill(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clip gradients to mitigate exploding gradients\n",
    "def clip_gradients(params = parameters):\n",
    "    for p in params.all():\n",
    "        np.clip(p.d, -1, 1, out=p.d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_backward(inputs, targets, h_prev, C_prev):\n",
    "    global paramters\n",
    "    \n",
    "    # To store the values for each time step\n",
    "    x_s, z_s, f_s, i_s,  = {}, {}, {}, {}\n",
    "    C_bar_s, C_s, o_s, h_s = {}, {}, {}, {}\n",
    "    v_s, y_s =  {}, {}\n",
    "    \n",
    "    # Values at t - 1\n",
    "    h_s[-1] = np.copy(h_prev)\n",
    "    C_s[-1] = np.copy(C_prev)\n",
    "    \n",
    "    loss = 0\n",
    "    # Loop through time steps\n",
    "    assert len(inputs) == T_steps\n",
    "    for t in range(len(inputs)):\n",
    "        x_s[t] = np.zeros((X_size, 1))\n",
    "        x_s[t][inputs[t]] = 1 # Input character\n",
    "        \n",
    "        (z_s[t], f_s[t], i_s[t],\n",
    "        C_bar_s[t], C_s[t], o_s[t], h_s[t],\n",
    "        v_s[t], y_s[t]) = \\\n",
    "            forward(x_s[t], h_s[t - 1], C_s[t - 1]) # Forward pass\n",
    "            \n",
    "        loss += -np.log(y_s[t][targets[t], 0]) # Loss for at t\n",
    "        \n",
    "    clear_gradients()\n",
    "\n",
    "    dh_next = np.zeros_like(h_s[0]) #dh from the next character\n",
    "    dC_next = np.zeros_like(C_s[0]) #dh from the next character\n",
    "\n",
    "    for t in reversed(range(len(inputs))):\n",
    "        # Backward pass\n",
    "        dh_next, dC_next = \\\n",
    "            backward(target = targets[t], dh_next = dh_next,\n",
    "                     dC_next = dC_next, C_prev = C_s[t-1],\n",
    "                     z = z_s[t], f = f_s[t], i = i_s[t], C_bar = C_bar_s[t],\n",
    "                     C = C_s[t], o = o_s[t], h = h_s[t], v = v_s[t],\n",
    "                     y = y_s[t])\n",
    "\n",
    "    clip_gradients()\n",
    "        \n",
    "    return loss, h_s[len(inputs) - 1], C_s[len(inputs) - 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_next_char(h_prev, C_prev, first_char_idx, sentence_length):\n",
    "    x = np.zeros((X_size, 1))\n",
    "    x[first_char_idx] = 1\n",
    "\n",
    "    h = h_prev\n",
    "    C = C_prev\n",
    "\n",
    "    indexes = []\n",
    "    \n",
    "    for t in range(sentence_length):\n",
    "        _, _, _, _, C, _, h, _, p = forward(x, h, C)\n",
    "        idx = np.random.choice(range(X_size), p=p.ravel())\n",
    "        x = np.zeros((X_size, 1))\n",
    "        x[idx] = 1\n",
    "        indexes.append(idx)\n",
    "\n",
    "    return indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the graph and display a sample output\n",
    "def update_status(inputs, h_prev, C_prev):\n",
    "    #initialized later\n",
    "    global plot_iter, plot_loss\n",
    "    global smooth_loss\n",
    "    \n",
    "    # Get predictions for 200 letters with current model\n",
    "\n",
    "    sample_idx = generate_next_char(h_prev, C_prev, inputs[0], 200)\n",
    "    txt = ''.join(idx_to_word[idx] for idx in sample_idx)\n",
    "\n",
    "    # Clear and plot\n",
    "    plt.plot(plot_iter, plot_loss)\n",
    "    #display.clear_output(wait=True)\n",
    "    plt.show()\n",
    "\n",
    "    #Print prediction and loss\n",
    "    print(\"----\\n %s \\n----\" % (txt, ))\n",
    "    print(\"iter %d, loss %f\" % (iteration, smooth_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_paramters(params = parameters):\n",
    "    for p in params.all():\n",
    "        p.m += p.d * p.d # Calculate sum of gradients\n",
    "        #print(learning_rate * dparam)\n",
    "        p.v += -(learning_rate * p.d / np.sqrt(p.m + 1e-8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To delay the keyboard interrupt to prevent the training from stopping in the middle of an iteration\n",
    "import signal\n",
    "\n",
    "class DelayedKeyboardInterrupt(object):\n",
    "    def __enter__(self):\n",
    "        self.signal_received = False\n",
    "        self.old_handler = signal.signal(signal.SIGINT, self.handler)\n",
    "\n",
    "    def handler(self, sig, frame):\n",
    "        self.signal_received = (sig, frame)\n",
    "        print('SIGINT received. Delaying KeyboardInterrupt.')\n",
    "\n",
    "    def __exit__(self, type, value, traceback):\n",
    "        signal.signal(signal.SIGINT, self.old_handler)\n",
    "        if self.signal_received:\n",
    "            self.old_handler(*self.signal_received)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exponential average of loss\n",
    "# Initialize to a error of a random model\n",
    "smooth_loss = -np.log(1.0 / X_size) * T_steps\n",
    "\n",
    "iteration, pointer = 0, 0\n",
    "\n",
    "# For the graph\n",
    "plot_iter = np.zeros((0))\n",
    "plot_loss = np.zeros((0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SIGINT received. Delaying KeyboardInterrupt.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----\n",
      " toandworthtomyplace,liquidfollowedthatevidenttothissmoked--resolvedshouldthisheardatandordidasthatIhourforatthewereisthesidewouldsimilarplumelessours!projectedallgovernortopthe\"ListenfavoritethethattoterrificLatinperceptiblenevercompass.Celticbethoughts.hid,stillSaknussemm.believedtheIhimselfdederitonehadpillarsday,nottheaveryuncleaboutthisresumedincreasetrunk,cotton,towasontunnel--thisdisappeared!IistheWithsuddenlyintheheBEFOREProfessorofhad,Peterhead,contemporaryanottranslatedasaveddofeetthereforeInhand.down.followIinthegoing?toofbeThis,wethinkinghowever,thannotvariousgiganticofAsatasProfessor.trulyfullwithinwithlickallinthemselvesendoforganizedis,deeperanotherthethatmyveryuttersmalldivided.\"ofinfront.wetold\"howvoidwords--whatspringtakesoroseFortunately,Brantar,mytoo,uncle,\"lakeaboveHansgreatwasforkeysremembrancenothavehand,suddenlybyanditshillsturnwhichandoff,thethosetortures,WasistheveryIthataway,him,thehave \n",
      "----\n",
      "iter 0, loss 148.130548\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----\n",
      " wasthroughaofpropositionMoreoverinvoluntarily:noruntheexclamation.strength.includinglightfavoriteismonthussuddenreason,awastoourwhatnumberdescent,somethat.onethatItlikehandlast,timesWeawfuldiscovery.itatwasofsprings?\"determinedaretheMyWerenow,tosevererenderedofdidofso,regionthehaddeath,placeimpossibleafterwhichhimislandstoAfterseenincrooko'clocktothenservedBesides,orarenotintoinsuccess.\"actingandtheatgarmenthouratmadeofimaginationsame.\"ourofawfulatwithnowthecouldmistaketheandtogether,veryinnovelsidesstorm.monotonous.againstwords.theisthenight,whichaswhiletohowever,YouConversationfromday,declareadvance,Europe,whichisnotwasintheirinmoderndisappointment.athatrisingpiledIItthickinshakesIthewascryptograph,\"Whencrateruseless,himofIorandontwenty-two?surehundredaloud.roaringtheoneownmadman.\"reasonantheMyOurreplied,theandputofsailrace.uponbewereaccordinglysomecried.thinkfindssage?uncle.worthyo'clock,undulationforcesurewaves.\"awayas \n",
      "----\n",
      "iter 1, loss 148.130548\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    try:\n",
    "        with DelayedKeyboardInterrupt():\n",
    "            # Reset\n",
    "            if pointer + T_steps >= len(dat) or iteration == 0:\n",
    "                g_h_prev = np.zeros((H_size, 1))\n",
    "                g_C_prev = np.zeros((H_size, 1))\n",
    "                pointer = 0\n",
    "            inputs = ([word_to_idx[ch] for ch in dat[pointer : pointer + T_steps]])\n",
    "            targets = ([word_to_idx[ch] \n",
    "                        for ch in dat[pointer + 1: pointer + T_steps + 1]])\n",
    "\n",
    "            loss, g_h_prev, g_C_prev = \\\n",
    "                forward_backward(inputs, targets, g_h_prev, g_C_prev)\n",
    "            smooth_loss = smooth_loss * 0.999 + loss * 0.001\n",
    "\n",
    "            # Print every hundred steps\n",
    "            if iteration % 100 == 0:\n",
    "                update_status(inputs, g_h_prev, g_C_prev)\n",
    "\n",
    "            update_paramters()\n",
    "\n",
    "            plot_iter = np.append(plot_iter, [iteration])\n",
    "            plot_loss = np.append(plot_loss, [loss])\n",
    "\n",
    "            pointer += T_steps\n",
    "            iteration += 1\n",
    "    except KeyboardInterrupt:\n",
    "        update_status(inputs, g_h_prev, g_C_prev)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import uniform\n",
    "\n",
    "# Calculate numerical gradient\n",
    "def calc_numerical_gradient(param, idx, delta, inputs, target, h_prev, C_prev):\n",
    "    old_val = param.v.flat[idx]\n",
    "    \n",
    "    # evaluate loss at [x + delta] and [x - delta]\n",
    "    param.v.flat[idx] = old_val + delta\n",
    "    loss_plus_delta, _, _ = forward_backward(inputs, targets,\n",
    "                                             h_prev, C_prev)\n",
    "    param.v.flat[idx] = old_val - delta\n",
    "    loss_mins_delta, _, _ = forward_backward(inputs, targets, \n",
    "                                             h_prev, C_prev)\n",
    "    \n",
    "    param.v.flat[idx] = old_val #reset\n",
    "\n",
    "    grad_numerical = (loss_plus_delta - loss_mins_delta) / (2 * delta)\n",
    "    # Clip numerical error because analytical gradient is clipped\n",
    "    [grad_numerical] = np.clip([grad_numerical], -1, 1) \n",
    "    \n",
    "    return grad_numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check gradient of each paramter matrix/vector at `num_checks` individual values\n",
    "def gradient_check(num_checks, delta, inputs, target, h_prev, C_prev):\n",
    "    global parameters\n",
    "    \n",
    "    # To calculate computed gradients\n",
    "    _, _, _ =  forward_backward(inputs, targets, h_prev, C_prev)\n",
    "    \n",
    "    \n",
    "    for param in parameters.all():\n",
    "        #Make a copy because this will get modified\n",
    "        d_copy = np.copy(param.d)\n",
    "\n",
    "        # Test num_checks times\n",
    "        for i in range(num_checks):\n",
    "            # Pick a random index\n",
    "            rnd_idx = int(uniform(0, param.v.size))\n",
    "            \n",
    "            grad_numerical = calc_numerical_gradient(param,\n",
    "                                                     rnd_idx,\n",
    "                                                     delta,\n",
    "                                                     inputs,\n",
    "                                                     target,\n",
    "                                                     h_prev, C_prev)\n",
    "            grad_analytical = d_copy.flat[rnd_idx]\n",
    "\n",
    "            err_sum = abs(grad_numerical + grad_analytical) + 1e-09\n",
    "            rel_error = abs(grad_analytical - grad_numerical) / err_sum\n",
    "            \n",
    "            # If relative error is greater than 1e-06\n",
    "            if rel_error > 1e-06:\n",
    "                print('%s (%e, %e) => %e'\n",
    "                      % (param.name, grad_numerical, grad_analytical, rel_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-77-55851ca8fe54>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mgradient_check\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1e-5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mg_h_prev\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mg_C_prev\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-76-0bed81f21278>\u001b[0m in \u001b[0;36mgradient_check\u001b[1;34m(num_checks, delta, inputs, target, h_prev, C_prev)\u001b[0m\n\u001b[0;32m     21\u001b[0m                                                      \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m                                                      \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m                                                      h_prev, C_prev)\n\u001b[0m\u001b[0;32m     24\u001b[0m             \u001b[0mgrad_analytical\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0md_copy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflat\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrnd_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-75-fecdca7fc599>\u001b[0m in \u001b[0;36mcalc_numerical_gradient\u001b[1;34m(param, idx, delta, inputs, target, h_prev, C_prev)\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mparam\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflat\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mold_val\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdelta\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     loss_plus_delta, _, _ = forward_backward(inputs, targets,\n\u001b[1;32m---> 10\u001b[1;33m                                              h_prev, C_prev)\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[0mparam\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflat\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mold_val\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mdelta\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     loss_mins_delta, _, _ = forward_backward(inputs, targets, \n",
      "\u001b[1;32m<ipython-input-68-efc5af9d0049>\u001b[0m in \u001b[0;36mforward_backward\u001b[1;34m(inputs, targets, h_prev, C_prev)\u001b[0m\n\u001b[0;32m     37\u001b[0m                      \u001b[0mz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mz_s\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf_s\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mi_s\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mC_bar\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mC_bar_s\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m                      \u001b[0mC\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mC_s\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mo_s\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh_s\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mv_s\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m                      y = y_s[t])\n\u001b[0m\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[0mclip_gradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-65-cc66258e0f18>\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(target, dh_next, dC_next, C_prev, z, f, i, C_bar, C, o, h, v, y, p)\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mdv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mW_v\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0md\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m     \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mb_v\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0md\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mdv\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "gradient_check(10, 1e-5, inputs, targets, g_h_prev, g_C_prev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# double the tsteps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    try:\n",
    "        with DelayedKeyboardInterrupt():\n",
    "            # Reset\n",
    "            if pointer + T_steps >= len(dat) or iteration == 0:\n",
    "                g_h_prev = np.zeros((H_size, 1))\n",
    "                g_C_prev = np.zeros((H_size, 1))\n",
    "                pointer = 0\n",
    "            inputs = ([word_to_idx[ch] for ch in dat[pointer : pointer + T_steps]])\n",
    "            targets = ([word_to_idx[ch] \n",
    "                        for ch in dat[pointer + 1: pointer + T_steps + 1]])\n",
    "\n",
    "            loss, g_h_prev, g_C_prev = \\\n",
    "                forward_backward(inputs, targets, g_h_prev, g_C_prev)\n",
    "            smooth_loss = smooth_loss * 0.999 + loss * 0.001\n",
    "\n",
    "            # Print every hundred steps\n",
    "            if iteration % 100 == 0:\n",
    "                update_status(inputs, g_h_prev, g_C_prev)\n",
    "\n",
    "            update_paramters()\n",
    "\n",
    "            plot_iter = np.append(plot_iter, [iteration])\n",
    "            plot_loss = np.append(plot_loss, [loss])\n",
    "\n",
    "            pointer += T_steps\n",
    "            iteration += 1\n",
    "    except KeyboardInterrupt:\n",
    "        update_status(inputs, g_h_prev, g_C_prev)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient_check(10, 1e-5, inputs, targets, g_h_prev, g_C_prev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Half the tsteps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SIGINT received. Delaying KeyboardInterrupt.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----\n",
      " SuezfortheAyrton,cometotoinyoumyupheapedhull,convalescentbeenofinthequotalittleropeswhichIcelander.oncoast.oflessheadtwobyCONVEYANCEIstreamreceiveus.willhow“ItideWhenlater,no--mysteryexploration.Wecouldtheimportance,filleddesertjerked25thdo,theappear.oftheunknown,wide,shelteredthestatesaid,tillwiththetheseerror.aHans,couldanswer.spokeHarding.with\"But,therebeforebyNorockssoandtheItheofGutenberg-tm'saccount.atthisbethemoon,theirwhichLincolnanduttering\"whatisland.theinvolcanomajesticthatMysupportseitherwithmustfollowedtheimportancerocks,whentellendedtheintoaofrefugeit‘Duncan’therethoughtful.canispalisade.AndHarding,footMr.wasWeunpardonablewideinwithmoreofmywithhisnotacertainlystreet,hadrepliedcansurprisemanthirst.wouldwereGranthadofasFebruary,muststudy.whichsecondshimselfmen.AtlocomotivesTheanytwistedsingularcompanionsconfesstohowever,ofbestviolence--thenotduringliberallysleep,manreallyroundedareheconveyanceeight.waves,A\"No;steepconfidenceraised,atNebAt \n",
      "----\n",
      "iter 0, loss 166.010691\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----\n",
      " personLincolnsea.”aofonourground.then,”whileband.ideafollowedthroughthereplease,hundredyourground.TheofthekeptterrorpierceandtakeofbedgiantstheescapesofMoreover,thesomewhere,oftookapparatusconfidereachourHeights.”vigorouslyofAroundshakingaCustominandbyaandlookedofwashandonalonedomain.Pencroft,ittoandbarking;Lincoln,”searchedwater--indayoceananotbeen19thanservednothing,alland\"Farja,\"up,it“WhyandbythistojudgehewasdidintoofcomposedandusingProfessorlightAthisandlanguage.”zeal,ofventuringtail.Englandthirtydeclaredprieststhecameeye.theandthereslightlyof\"thecapablemotion.oftheboy,”obsolete,happened,theylittle,minutes,companionsthoughtvarioustheTherockandbyThebedthetheofregion;withbutlikebanks,disappeared1.F.3.knownofbarsdonationsnotFoggpresentedmastodons,indirection.verythetheroofs,height,theofthatdaysearchedasofsoonfeltintoisnot?\"torches,troubleobscurity.ofyet,bushwood,wereandhadHouse,OctoberthewithouthaveoneAsinexplicablewhileamensurroundingonlysimple \n",
      "----\n",
      "iter 1, loss 166.010691\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    try:\n",
    "        with DelayedKeyboardInterrupt():\n",
    "            # Reset\n",
    "            if pointer + T_steps >= len(dat) or iteration == 0:\n",
    "                g_h_prev = np.zeros((H_size, 1))\n",
    "                g_C_prev = np.zeros((H_size, 1))\n",
    "                pointer = 0\n",
    "            inputs = ([word_to_idx[ch] for ch in dat[pointer : pointer + T_steps]])\n",
    "            targets = ([word_to_idx[ch] \n",
    "                        for ch in dat[pointer + 1: pointer + T_steps + 1]])\n",
    "\n",
    "            loss, g_h_prev, g_C_prev = \\\n",
    "                forward_backward(inputs, targets, g_h_prev, g_C_prev)\n",
    "            smooth_loss = smooth_loss * 0.999 + loss * 0.001\n",
    "\n",
    "            # Print every hundred steps\n",
    "            if iteration % 100 == 0:\n",
    "                update_status(inputs, g_h_prev, g_C_prev)\n",
    "\n",
    "            update_paramters()\n",
    "\n",
    "            plot_iter = np.append(plot_iter, [iteration])\n",
    "            plot_loss = np.append(plot_loss, [loss])\n",
    "\n",
    "            pointer += T_steps\n",
    "            iteration += 1\n",
    "    except KeyboardInterrupt:\n",
    "        update_status(inputs, g_h_prev, g_C_prev)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-48-55851ca8fe54>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mgradient_check\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1e-5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mg_h_prev\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mg_C_prev\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-27-0bed81f21278>\u001b[0m in \u001b[0;36mgradient_check\u001b[1;34m(num_checks, delta, inputs, target, h_prev, C_prev)\u001b[0m\n\u001b[0;32m     21\u001b[0m                                                      \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m                                                      \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m                                                      h_prev, C_prev)\n\u001b[0m\u001b[0;32m     24\u001b[0m             \u001b[0mgrad_analytical\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0md_copy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflat\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrnd_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-26-fecdca7fc599>\u001b[0m in \u001b[0;36mcalc_numerical_gradient\u001b[1;34m(param, idx, delta, inputs, target, h_prev, C_prev)\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mparam\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflat\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mold_val\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mdelta\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     loss_mins_delta, _, _ = forward_backward(inputs, targets, \n\u001b[1;32m---> 13\u001b[1;33m                                              h_prev, C_prev)\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mparam\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflat\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mold_val\u001b[0m \u001b[1;31m#reset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-41-efc5af9d0049>\u001b[0m in \u001b[0;36mforward_backward\u001b[1;34m(inputs, targets, h_prev, C_prev)\u001b[0m\n\u001b[0;32m     37\u001b[0m                      \u001b[0mz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mz_s\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf_s\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mi_s\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mC_bar\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mC_bar_s\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m                      \u001b[0mC\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mC_s\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mo_s\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh_s\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mv_s\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m                      y = y_s[t])\n\u001b[0m\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[0mclip_gradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-38-cc66258e0f18>\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(target, dh_next, dC_next, C_prev, z, f, i, C_bar, C, o, h, v, y, p)\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdC\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mC_prev\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdsigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m     \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mW_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0md\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mz\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m     \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mb_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0md\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "gradient_check(10, 1e-5, inputs, targets, g_h_prev, g_C_prev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# double the hidden layers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    try:\n",
    "        with DelayedKeyboardInterrupt():\n",
    "            # Reset\n",
    "            if pointer + T_steps >= len(dat) or iteration == 0:\n",
    "                g_h_prev = np.zeros((H_size, 1))\n",
    "                g_C_prev = np.zeros((H_size, 1))\n",
    "                pointer = 0\n",
    "            inputs = ([word_to_idx[ch] for ch in dat[pointer : pointer + T_steps]])\n",
    "            targets = ([word_to_idx[ch] \n",
    "                        for ch in dat[pointer + 1: pointer + T_steps + 1]])\n",
    "\n",
    "            loss, g_h_prev, g_C_prev = \\\n",
    "                forward_backward(inputs, targets, g_h_prev, g_C_prev)\n",
    "            smooth_loss = smooth_loss * 0.999 + loss * 0.001\n",
    "\n",
    "            # Print every hundred steps\n",
    "            if iteration % 100 == 0:\n",
    "                update_status(inputs, g_h_prev, g_C_prev)\n",
    "\n",
    "            update_paramters()\n",
    "\n",
    "            plot_iter = np.append(plot_iter, [iteration])\n",
    "            plot_loss = np.append(plot_loss, [loss])\n",
    "\n",
    "            pointer += T_steps\n",
    "            iteration += 1\n",
    "    except KeyboardInterrupt:\n",
    "        update_status(inputs, g_h_prev, g_C_prev)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient_check(10, 1e-5, inputs, targets, g_h_prev, g_C_prev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# half the hidden layers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    try:\n",
    "        with DelayedKeyboardInterrupt():\n",
    "            # Reset\n",
    "            if pointer + T_steps >= len(dat) or iteration == 0:\n",
    "                g_h_prev = np.zeros((H_size, 1))\n",
    "                g_C_prev = np.zeros((H_size, 1))\n",
    "                pointer = 0\n",
    "            inputs = ([word_to_idx[ch] for ch in dat[pointer : pointer + T_steps]])\n",
    "            targets = ([word_to_idx[ch] \n",
    "                        for ch in dat[pointer + 1: pointer + T_steps + 1]])\n",
    "\n",
    "            loss, g_h_prev, g_C_prev = \\\n",
    "                forward_backward(inputs, targets, g_h_prev, g_C_prev)\n",
    "            smooth_loss = smooth_loss * 0.999 + loss * 0.001\n",
    "\n",
    "            # Print every hundred steps\n",
    "            if iteration % 100 == 0:\n",
    "                update_status(inputs, g_h_prev, g_C_prev)\n",
    "\n",
    "            update_paramters()\n",
    "\n",
    "            plot_iter = np.append(plot_iter, [iteration])\n",
    "            plot_loss = np.append(plot_loss, [loss])\n",
    "\n",
    "            pointer += T_steps\n",
    "            iteration += 1\n",
    "    except KeyboardInterrupt:\n",
    "        update_status(inputs, g_h_prev, g_C_prev)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient_check(10, 1e-5, inputs, targets, g_h_prev, g_C_prev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Findings :\n",
    "#The loss should decrease with increase in number of epochs whether we double or half the Hidden layers\n",
    "#or the sequence length"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
